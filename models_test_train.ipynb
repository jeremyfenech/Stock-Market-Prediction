{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import talib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the maximum number of files to import\n",
    "n_files = 10\n",
    "\n",
    "# Get a list of all CSV files in the directory\n",
    "file_list = glob.glob('stock_archive/stock_market_data/**/**/*.csv')\n",
    "\n",
    "\n",
    "# Sort the file list (optional)\n",
    "file_list.sort()\n",
    "\n",
    "# Initialize an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Iterate over the specified number of files\n",
    "for file in file_list[:n_files]:\n",
    "    df = pd.read_csv(file, on_bad_lines='skip')\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate the DataFrames into a single DataFrame\n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Print the size of combined DataFrame\n",
    "print(f\"Size of dataset: {len(data)}\\n\")\n",
    "\n",
    "# Calculate Log Returns\n",
    "data['LogReturns'] = np.log(data['Adjusted Close'] / data['Adjusted Close'].shift(1))\n",
    "\n",
    "# Calculate TEMA\n",
    "data['TEMA'] = talib.TEMA(data['Adjusted Close'], timeperiod=20)\n",
    "\n",
    "# Calculate Simple Moving Average (SMA)\n",
    "data['SMA_10'] = talib.SMA(data['Adjusted Close'], timeperiod=10)\n",
    "\n",
    "# Calculate Exponential Moving Average (EMA)\n",
    "data['EMA_20'] = talib.EMA(data['Adjusted Close'], timeperiod=20)\n",
    "\n",
    "# Calculate RSI\n",
    "data['RSI'] = talib.RSI(data['Adjusted Close'], timeperiod=14)\n",
    "\n",
    "# Calculate MACD\n",
    "macd, macd_signal, macd_histogram = talib.MACD(data['Adjusted Close'])\n",
    "data['MACD'] = macd\n",
    "data['MACD_Signal'] = macd_signal\n",
    "data['MACD_Histogram'] = macd_histogram\n",
    "\n",
    "# Drop data which had NaN values\n",
    "# Since identifiers like TEMA take timeperiod 20 the last\n",
    "# 20 rows atleast will always have NaN values\n",
    "data = data.dropna()\n",
    "\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = data.drop(['Date'], axis=1)  # Input features\n",
    "y = data['Adjusted Close'].shift(-20)  # Target variables shifted by one day\n",
    "\n",
    "# Remove the last row from X and y\n",
    "X = X[:-20]\n",
    "y = y[:-20]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2)\n",
    "\n",
    "# MODEL TRAINING AND EVALUATION\n",
    "\n",
    "\n",
    "# RANDOM FOREST\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rf_mse = mean_squared_error(y_test, rf_predictions)\n",
    "rf_rmse = mean_squared_error(y_test, rf_predictions, squared=False)\n",
    "rf_mae = mean_absolute_error(y_test, rf_predictions)\n",
    "rf_r2 = r2_score(y_test, rf_predictions)\n",
    "\n",
    "print(\"Random Forest Metrics:\")\n",
    "print(\"MSE:\", rf_mse)\n",
    "print(\"RMSE:\", rf_rmse)\n",
    "print(\"MAE:\", rf_mae)\n",
    "print(\"R-squared:\", rf_r2)\n",
    "\n",
    "\n",
    "# GRADIENT BOOSTING\n",
    "\n",
    "# Initialize the Gradient Boosting model\n",
    "gb_model = GradientBoostingRegressor()\n",
    "\n",
    "# Train the Gradient Boosting model\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "gb_predictions = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "gb_mse = mean_squared_error(y_test, gb_predictions)\n",
    "gb_rmse = mean_squared_error(y_test, gb_predictions, squared=False)\n",
    "gb_mae = mean_absolute_error(y_test, gb_predictions)\n",
    "gb_r2 = r2_score(y_test, gb_predictions)\n",
    "\n",
    "print(\"\\nGradient Boosting Metrics:\")\n",
    "print(\"MSE:\", gb_mse)\n",
    "print(\"RMSE:\", gb_rmse)\n",
    "print(\"MAE:\", gb_mae)\n",
    "print(\"R-squared:\", gb_r2)\n",
    "\n",
    "# LINEAR REGRESSION\n",
    "\n",
    "# Create an instance of LinearRegression\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "lr_predictions = linear_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "lr_rmse = mean_squared_error(y_test, lr_predictions, squared=False)\n",
    "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
    "lr_r2 = r2_score(y_test, lr_predictions)\n",
    "\n",
    "print(\"\\nLinear Regression Metrics:\")\n",
    "print(\"MSE:\", lr_mse)\n",
    "print(\"RMSE:\", lr_rmse)\n",
    "print(\"MAE:\", lr_mae)\n",
    "print(\"R-squared:\", lr_r2)\n",
    "\n",
    "# LONG SHORT TERM MEMORY (LSTM)\n",
    "\n",
    "# Reshape the data for LSTM input shape (samples, time steps, features)\n",
    "X_train_lstm = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_lstm = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Initialize the LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(64, input_shape=(1, X_train.shape[1])))\n",
    "lstm_model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "lstm_model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# Train the LSTM model\n",
    "lstm_model.fit(X_train_lstm, y_train, epochs=10, batch_size=32, use_multiprocessing=True, verbose=0)\n",
    "\n",
    "# Make predictions on the test set\n",
    "lstm_predictions = lstm_model.predict(X_test_lstm, use_multiprocessing=True, verbose=0)\n",
    "\n",
    "# Reshape the predictions back to 1D array\n",
    "lstm_predictions = lstm_predictions.flatten()\n",
    "\n",
    "# Evaluate the model\n",
    "lstm_mse = mean_squared_error(y_test, lstm_predictions)\n",
    "lstm_rmse = mean_squared_error(y_test, lstm_predictions, squared=False)\n",
    "lstm_mae = mean_absolute_error(y_test, lstm_predictions)\n",
    "lstm_r2 = r2_score(y_test, lstm_predictions)\n",
    "\n",
    "print(\"\\nLong Short Term Memory (LSTM) Metrics:\")\n",
    "print(\"MSE:\", lstm_mse)\n",
    "print(\"RMSE:\", lstm_rmse)\n",
    "print(\"MAE:\", lstm_mae)\n",
    "print(\"R-squared:\", lstm_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 24614702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set the maximum number of files to import\n",
    "# Commented to train with all files\n",
    "# n_files = 1\n",
    "\n",
    "# Get a list of all CSV files in the directory\n",
    "file_list = glob.glob('stock_archive/stock_market_data/**/**/*.csv')\n",
    "\n",
    "# Sort the file list (optional)\n",
    "file_list.sort()\n",
    "\n",
    "# Initialize an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Iterate over the specified number of files\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file, on_bad_lines='skip')\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate the DataFrames into a single DataFrame\n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Print the size of combined DataFrame\n",
    "print(f\"Size of dataset: {len(data)}\\n\")\n",
    "\n",
    "# Calculate Log Returns\n",
    "data['LogReturns'] = np.log(data['Adjusted Close'] / data['Adjusted Close'].shift(1))\n",
    "\n",
    "# Calculate TEMA\n",
    "data['TEMA'] = talib.TEMA(data['Adjusted Close'], timeperiod=20)\n",
    "\n",
    "# Calculate Simple Moving Average (SMA)\n",
    "data['SMA_10'] = talib.SMA(data['Adjusted Close'], timeperiod=10)\n",
    "\n",
    "# Calculate Exponential Moving Average (EMA)\n",
    "data['EMA_20'] = talib.EMA(data['Adjusted Close'], timeperiod=20)\n",
    "\n",
    "# Calculate RSI\n",
    "data['RSI'] = talib.RSI(data['Adjusted Close'], timeperiod=14)\n",
    "\n",
    "# Calculate MACD\n",
    "macd, macd_signal, macd_histogram = talib.MACD(data['Adjusted Close'])\n",
    "data['MACD'] = macd\n",
    "data['MACD_Signal'] = macd_signal\n",
    "data['MACD_Histogram'] = macd_histogram\n",
    "\n",
    "# Drop data which had NaN values\n",
    "# Since identifiers like TEMA take timeperiod 20 the last\n",
    "# 20 rows atleast will always have NaN values\n",
    "data = data.dropna()\n",
    "\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = data.drop(['Date'], axis=1)  # Input features\n",
    "y = data['Adjusted Close'].shift(-20)  # Target variables shifted by n days\n",
    "\n",
    "# Remove the last n rows from X and y\n",
    "X = X[:-20]\n",
    "y = y[:-20]\n",
    "\n",
    "\n",
    "# MODEL TRAINING\n",
    "\n",
    "\n",
    "# RANDOM FOREST\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "# Export the model to a file\n",
    "joblib.dump(rf_model, 'models/random_forest_model.joblib')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
